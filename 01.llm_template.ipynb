{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4a4dce",
   "metadata": {},
   "source": [
    "# How to start\n",
    "\n",
    "We'll use Ollama to avoid expenses associated with LLM like GPT. No need API keys.\n",
    "\n",
    "The version of LangChain installed should be 0.3+\n",
    "\n",
    "Ollama [is easy to install using Docker](https://github.com/ollama/ollama/blob/main/docs/docker.md). \n",
    "(Better to have a GPU, even a small one)\n",
    "\n",
    "I give an example of Dockerfile and docker-compose.yaml using Python 3.12\n",
    "\n",
    "You can then use an evironment variable OLLAMA_SERVER (ex. OLLAMA_SERVER='http://ollama:11434') from this container [running Jupyter](https://jupyterlab.readthedocs.io/en/4.1.x/getting_started/installation.html)\n",
    "\n",
    "# Talk to the LLM\n",
    "We will follow the [LangChain examples](https://python.langchain.com/docs/tutorials/llm_chain/) and adapt them a little to work with Ollama\n",
    " \n",
    "1) We set up the necessary libraries and connects to the Ollama server. It checks the LangChain version to ensure compatibility.\n",
    "2) Initializes the language model with specific settings.\n",
    "3) Creates a template that tells the model to respond in a certain language and includes a placeholder for user questions.\n",
    "4) Ask a question in a specific language and sends it to the model.\n",
    "5) Finally, it prints the model's response, showing how to get answers in the desired language.\n",
    "\n",
    "# We need\n",
    "\n",
    "- `langchain` The core LangChain library.\n",
    "- `ChatOllama`: The ChatOllama class for using Ollama models.\n",
    "- `ChatPromptTemplate`: ChatPromptTemplate for creating chat prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2de674c4-d55f-43ee-9ae4-dcbfb15a3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e31bb91f-0dcf-4f6f-92a9-a1f6c19c3e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.14\n"
     ]
    }
   ],
   "source": [
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4f2d11f-b3e2-466f-8b7d-846164b78c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(base_url=os.getenv(\"OLLAMA_SERVER\"),model = \"llama3.2:latest\",temperature = 0.8,num_predict = 256,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a7545c2-280e-48fd-b341-3b7d6c756248",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Always answer in {language}\"\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "832e33ff-096b-4dd4-a7ed-236bf375d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"French\", \"text\": \"C'est où la Belgique?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51e2d309-b541-45ea-b85b-aa3045b984fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Always answer in French', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"C'est où la Belgique?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a544961-1131-4ea3-9ff0-7e66f22601ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feb6b0f4-e0b7-4601-88bf-221101c53645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Belgique est un petit pays situé en Europe de l'Ouest, bordé par les pays suivants : \n",
      "\n",
      "- Au nord et à l'ouest, il partage une frontière avec le pays des Pays-Bas.\n",
      "- À l'est, la Belgique est limitée par l'Allemagne.\n",
      "- Au sud, elle est entourée par la France (mais pas directement), bien que les deux pays partagent une frontière indirecte via la commune de Wissembourg en Alsace.\n",
      "\n",
      "La Belgique est divisée en trois régions : \n",
      "- La Flandre au nord, qui compte environ 60% de la population.\n",
      "- Le Brabant flamand et le Brabant wallon à l'est.\n",
      "- La Wallonie et la Communauté française au sud.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42fae9-80e2-476e-adc9-b861493c31b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
