{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Agent\n",
    "\n",
    "The key difference between an agent and a pipeline lies in their flexibility and decision-making capabilities.\n",
    "\n",
    "Using “Agents” in frameworks like LangChain often introduces significant complexity. While the tool simplifies foundational tasks like API calls, stream handling, and vector database integration, the abstraction becomes overwhelming with agents.\n",
    "\n",
    "These entities aim to manage dynamic workflows by chaining multiple tasks, such as calling APIs, interacting with tools, or solving problems iteratively. However, this flexibility comes at a cost: increased dependencies, debugging difficulties, and convoluted configurations. \n",
    "\n",
    "Developers often find themselves navigating layers of abstractions that obscure the underlying logic, making it harder to maintain, optimize, or understand the system, especially for straightforward tasks.\n",
    "\n",
    "## Pipeline:\n",
    "\n",
    "- A pipeline is a fixed sequence of steps that always processes input in the same way.\n",
    "- Each step in a pipeline transforms the data and passes it to the next step.\n",
    "- Example: If you want to preprocess input, pass it to an LLM, and then clean the output, a pipeline will always follow this sequence, regardless of the task.\n",
    "\n",
    "Think of a pipeline as a well-defined assembly line where every step is predefined and linear.\n",
    "\n",
    "## Agent:\n",
    "- An agent is dynamic and can make decisions during execution.\n",
    "- It analyzes the input and decides what tools or actions to use based on the task.\n",
    "- Agents can use multiple tools or external resources (e.g., calculators, search engines) and switch between them as needed.\n",
    "- Example: If the user asks a question that involves math, the agent might use a calculator tool; if the user asks for a definition, it might query an LLM instead.\n",
    "\n",
    "Think of an agent as a problem solver that chooses the right tools for the job based on the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import llm # containing my ChatOllama\n",
    "from langchain.chains import TransformChain\n",
    "\n",
    "# Step 1: Preprocess input\n",
    "def preprocess(inputs):\n",
    "    return {\"input\": f\"You are a helpful assistant. {inputs['input']}\"}\n",
    "\n",
    "# Step 2: Pass to LLM\n",
    "def run_llm(inputs):\n",
    "    response = llm.invoke([{\"role\": \"user\", \"content\": inputs[\"input\"]}])\n",
    "    return {\"output\": response.content.strip()}\n",
    "\n",
    "# Step 3: Clean output\n",
    "def postprocess(inputs):\n",
    "    return {\"final_output\": inputs[\"output\"]}\n",
    "\n",
    "# Combine steps into a pipeline\n",
    "preprocess_chain = TransformChain(input_variables=[\"input\"], output_variables=[\"input\"], transform=preprocess)\n",
    "llm_chain = TransformChain(input_variables=[\"input\"], output_variables=[\"output\"], transform=run_llm)\n",
    "postprocess_chain = TransformChain(input_variables=[\"output\"], output_variables=[\"final_output\"], transform=postprocess)\n",
    "pipeline = preprocess_chain | llm_chain | postprocess_chain\n",
    "\n",
    "# Test the pipeline\n",
    "result = pipeline.invoke({\"input\": \"What is 2 + 2?\"})\n",
    "print(result[\"final_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing translate_tool\n",
      "{'input': \"Translate 'Hello' into French.\", 'output': 'Bonjour'}\n",
      "Executing calculator_tool\n",
      "Executing calculator_tool\n",
      "Executing calculator_tool\n",
      "Executing calculator_tool\n",
      "Executing translate_tool\n",
      "Executing translate_tool\n",
      "Executing translate_tool\n",
      "Executing translate_tool\n",
      "Executing calculator_tool\n",
      "Executing translate_tool\n",
      "Executing calculator_tool\n",
      "Executing translate_tool\n",
      "Executing translate_tool\n",
      "Executing translate_tool\n",
      "Executing calculator_tool\n",
      "{'input': 'What is 2 + 2?', 'output': 'Agent stopped due to iteration limit or time limit.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "# Define tools\n",
    "def translate_tool(text):\n",
    "    print(\"Executing translate_tool\")\n",
    "    return \"Bonjour\" if \"Hello\" in text else \"Unknown\"\n",
    "\n",
    "def calculator_tool(expression):\n",
    "    print(\"Executing calculator_tool\")\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception:\n",
    "        return \"Error\"\n",
    "\n",
    "# Initialize tools\n",
    "tools = [\n",
    "    Tool(name=\"Translator\", func=translate_tool, description=\"Translate English to French.\"),\n",
    "    Tool(name=\"Calculator\", func=calculator_tool, description=\"Perform math calculations.\")\n",
    "]\n",
    "\n",
    "# Initialize agent\n",
    "agent = initialize_agent(tools=tools, llm=llm, agent=\"zero-shot-react-description\")\n",
    "\n",
    "# Test the agent with invoke\n",
    "print(agent.invoke(\"Translate 'Hello' into French.\"))\n",
    "print(agent.invoke(\"What is 2 + 2?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main benefits of using an agent (initialize_agent) over a pipeline are flexibility, decision-making, and tool selection. Here’s how the agent in the given example compares to a pipeline:\n",
    "\n",
    "## Benefits of the Agent:\n",
    "\n",
    "### Dynamic Tool Selection:\n",
    "\n",
    "- The agent analyzes the input and decides which tool (e.g., Translator or Calculator) to use.\n",
    "- Example: For “Translate ‘Hello’ into French,” the agent uses the translate_tool, while for “What is 2 + 2?”, it uses the calculator_tool.\n",
    "- In contrast, a pipeline always follows the same steps in a fixed order, even if some steps are unnecessary.\n",
    "\n",
    "### Efficiency:\n",
    "\n",
    "- The agent avoids invoking the LLM unnecessarily. \n",
    "- For math operations, it uses the faster and more efficient calculator_tool instead of processing the task with the LLM.\n",
    "- A pipeline might waste resources by relying on the LLM for all tasks, regardless of the actual need.\n",
    "\n",
    "### Scalability:\n",
    "\n",
    "- An agent can handle a wide variety of tasks by adding more tools without requiring you to rewrite the logic.\n",
    "- A pipeline would need to be restructured if new steps or different logic were required for additional tasks.\n",
    "\n",
    "### Context-Aware Decision-Making:\n",
    "\n",
    "- The agent uses a reasoning framework (like “zero-shot-react-description”) to interpret the user query and determine the best course of action.\n",
    "- Pipelines do not interpret or make decisions; they simply process inputs linearly.\n",
    "\n",
    "### Simpler Logic for Complex Workflows:\n",
    "\n",
    "- Agents simplify workflows that require branching logic or tool selection.\n",
    "- Without an agent, you’d have to write custom branching logic (e.g., if statements) to decide which tool or step to execute in a pipeline.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
