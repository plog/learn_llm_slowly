{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Agent\n",
    "\n",
    "The key difference between an agent and a pipeline lies in their flexibility and decision-making capabilities.\n",
    "\n",
    "Using “Agents” in frameworks like LangChain often introduces significant complexity. While the tool simplifies foundational tasks like API calls, stream handling, and vector database integration, the abstraction becomes overwhelming with agents.\n",
    "\n",
    "These entities aim to manage dynamic workflows by chaining multiple tasks, such as calling APIs, interacting with tools, or solving problems iteratively. However, this flexibility comes at a cost: increased dependencies, debugging difficulties, and convoluted configurations. \n",
    "\n",
    "Developers often find themselves navigating layers of abstractions that obscure the underlying logic, making it harder to maintain, optimize, or understand the system, especially for straightforward tasks.\n",
    "\n",
    "## Pipeline:\n",
    "\n",
    "- A pipeline is a fixed sequence of steps that always processes input in the same way.\n",
    "- Each step in a pipeline transforms the data and passes it to the next step.\n",
    "- Example: If you want to preprocess input, pass it to an LLM, and then clean the output, a pipeline will always follow this sequence, regardless of the task.\n",
    "\n",
    "Think of a pipeline as a well-defined assembly line where every step is predefined and linear.\n",
    "\n",
    "## Agent:\n",
    "- An agent is dynamic and can make decisions during execution.\n",
    "- It analyzes the input and decides what tools or actions to use based on the task.\n",
    "- Agents can use multiple tools or external resources (e.g., calculators, search engines) and switch between them as needed.\n",
    "- Example: If the user asks a question that involves math, the agent might use a calculator tool; if the user asks for a definition, it might query an LLM instead.\n",
    "\n",
    "Think of an agent as a problem solver that chooses the right tools for the job based on the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import llm # containing my ChatOllama\n",
    "from langchain.chains import TransformChain\n",
    "\n",
    "# Step 1: Preprocess input\n",
    "def preprocess(inputs):\n",
    "    return {\"input\": f\"You are a helpful assistant. {inputs['input']}\"}\n",
    "\n",
    "# Step 2: Pass to LLM\n",
    "def run_llm(inputs):\n",
    "    response = llm.invoke([{\"role\": \"user\", \"content\": inputs[\"input\"]}])\n",
    "    return {\"output\": response.content.strip()}\n",
    "\n",
    "# Step 3: Clean output\n",
    "def postprocess(inputs):\n",
    "    return {\"final_output\": inputs[\"output\"]}\n",
    "\n",
    "# Combine steps into a pipeline\n",
    "preprocess_chain  = TransformChain(input_variables=[\"input\"], output_variables=[\"input\"], transform=preprocess)\n",
    "llm_chain         = TransformChain(input_variables=[\"input\"], output_variables=[\"output\"], transform=run_llm)\n",
    "postprocess_chain = TransformChain(input_variables=[\"output\"], output_variables=[\"final_output\"], transform=postprocess)\n",
    "pipeline          = preprocess_chain | llm_chain | postprocess_chain\n",
    "\n",
    "# Test the pipeline\n",
    "result = pipeline.invoke({\"input\": \"What is 2 + 2?\"})\n",
    "print(result[\"final_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import groq # We'll use Groq this time (it's late and Ollama is tired)\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe user wants me to translate a word into French. I can use the translate_tool for this task.\n",
      "Action: translate_tool\n",
      "Action Input: 'Hello'\u001b[0mExecuting translate_tool\n",
      "\u001b[36;1m\u001b[1;3mTranslated!\u001b[0m\u001b[32;1m\u001b[1;3mI now have the translation.\n",
      "Final Answer: Bonjour (French translation of 'Hello')\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"Translate 'Hello' into French.\", 'output': \"Bonjour (French translation of 'Hello')\"}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe user is asking for a mathematical calculation, which I can do using the calculator_tool.\n",
      "Action: calculator_tool\n",
      "Action Input: 2 + 2\u001b[0mExecuting calculator_tool\n",
      "\u001b[33;1m\u001b[1;3m4\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The result of 2 + 2 is 4.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is 2 + 2?', 'output': 'The result of 2 + 2 is 4.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def translate_tool(text):\n",
    "    \"\"\"\n",
    "    To get an English translation, it takes the user's query as arguments\n",
    "    query(str): string to translate\n",
    "    \"\"\"    \n",
    "    print(\"Executing translate_tool\")\n",
    "    return \"Translated!\" \n",
    "\n",
    "@tool\n",
    "def calculator_tool(expression):\n",
    "    \"\"\"\n",
    "    To calculate an expression, it takes the user's query as arguments\n",
    "    query(str): string to calculate\n",
    "    \"\"\"\n",
    "    print(\"Executing calculator_tool\")\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception:\n",
    "        return \"Error\"\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "tools = [translate_tool, calculator_tool]\n",
    "# Initialize agent\n",
    "agent = create_react_agent(groq,tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "\n",
    "# Test the agent with invoke\n",
    "print(agent_executor.invoke({\"input\":\"Translate 'Hello' into French.\"}))\n",
    "print(agent_executor.invoke({\"input\":\"What is 2 + 2?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main benefits of using an agent (initialize_agent) over a pipeline are flexibility, decision-making, and tool selection. Here’s how the agent in the given example compares to a pipeline:\n",
    "\n",
    "## Benefits of the Agent:\n",
    "\n",
    "### Dynamic Tool Selection:\n",
    "\n",
    "- The agent analyzes the input and decides which tool (e.g., Translator or Calculator) to use.\n",
    "- Example: For “Translate ‘Hello’ into French,” the agent uses the translate_tool, while for “What is 2 + 2?”, it uses the calculator_tool.\n",
    "- In contrast, a pipeline always follows the same steps in a fixed order, even if some steps are unnecessary.\n",
    "\n",
    "### Efficiency:\n",
    "\n",
    "- The agent avoids invoking the LLM unnecessarily. \n",
    "- For math operations, it uses the faster and more efficient calculator_tool instead of processing the task with the LLM.\n",
    "- A pipeline might waste resources by relying on the LLM for all tasks, regardless of the actual need.\n",
    "\n",
    "### Scalability:\n",
    "\n",
    "- An agent can handle a wide variety of tasks by adding more tools without requiring you to rewrite the logic.\n",
    "- A pipeline would need to be restructured if new steps or different logic were required for additional tasks.\n",
    "\n",
    "### Context-Aware Decision-Making:\n",
    "\n",
    "- The agent uses a reasoning framework (like “zero-shot-react-description”) to interpret the user query and determine the best course of action.\n",
    "- Pipelines do not interpret or make decisions; they simply process inputs linearly.\n",
    "\n",
    "### Simpler Logic for Complex Workflows:\n",
    "\n",
    "- Agents simplify workflows that require branching logic or tool selection.\n",
    "- Without an agent, you’d have to write custom branching logic (e.g., if statements) to decide which tool or step to execute in a pipeline.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
