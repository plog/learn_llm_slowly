{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Long-Term memory\n",
    "\n",
    "Must read:\n",
    "- [What is Memory?](https://langchain-ai.github.io/langgraph/concepts/memory/#what-is-memory)\n",
    "\n",
    "This code creates a chatbot that can remember things you tell it and use those memories to give better responses. \n",
    "\n",
    "1) Stores what you say in Qdrant after turning your words into vectors so the bot can find related information later.\n",
    "2) When you ask the bot something, it checks the database for anything related to your question. \n",
    "3) It uses this information, along with your current input, to create a reply that feels like it “remembers” past conversations. \n",
    "4) If you tell it to “remember” something, it saves both your words and its reply, so it can recall them in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "import uuid\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client.models import PointStruct\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client.models import PointStruct, VectorParams\n",
    "import os\n",
    "OLLAMA_SERVER = os.getenv(\"OLLAMA_SERVER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChatOllama and Qdrant client\n",
    "llm               = ChatOllama(base_url=OLLAMA_SERVER, model=\"mistral\", temperature=0.8)\n",
    "embeddings        = OllamaEmbeddings(base_url=OLLAMA_SERVER, model=\"mxbai-embed-large\")\n",
    "qdrant_client     = QdrantClient(host='lawboxai_qdrant')\n",
    "qdrant_collection = \"long_term_memory\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongTermMemoryManager:\n",
    "    def __init__(self, collection_name, qdrant_client, embeddings):\n",
    "        self.collection_name = collection_name\n",
    "        self.qdrant_client = qdrant_client\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "        # Create collection if it doesn't exist\n",
    "        if collection_name not in [c.name for c in qdrant_client.get_collections().collections]:\n",
    "            self.qdrant_client.create_collection(\n",
    "                collection_name=collection_name,\n",
    "                vectors_config=VectorParams(size=len(self.embeddings.embed_query(\"test\")),distance=\"Cosine\"))\n",
    "\n",
    "    def store_memory(self, content):\n",
    "        self.qdrant_client.upsert(\n",
    "            collection_name=self.collection_name,\n",
    "            points=[PointStruct(\n",
    "                id=str(uuid.uuid5(uuid.NAMESPACE_DNS, content)),\n",
    "                vector=self.embeddings.embed_query(content),\n",
    "                payload={\"content\": content}\n",
    "            )]\n",
    "        )\n",
    "\n",
    "    def retrieve_memory(self, query, top_k=3):\n",
    "        results = self.qdrant_client.query_points(\n",
    "            collection_name=self.collection_name,\n",
    "            query=self.embeddings.embed_query(query),\n",
    "            limit=top_k\n",
    "        )\n",
    "        return [point.payload[\"content\"] for point in results.points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"long_term_memory\"\n",
    "memory_manager = LongTermMemoryManager(collection_name, qdrant_client, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_memory(user_input):\n",
    "    # Retrieve relevant memories\n",
    "    relevant_memories = memory_manager.retrieve_memory(user_input)\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Please respond in French, and incorporate any relevant context from the following: \" + \" \".join(relevant_memories)\n",
    "    }\n",
    "    prompt = [\n",
    "        system_message,\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    response = llm.invoke(prompt)\n",
    "    ai_reply = response.content.strip()\n",
    "    if \"remember\" in user_input.lower():\n",
    "        memory_manager.store_memory(user_input)\n",
    "        memory_manager.store_memory(ai_reply)\n",
    "    \n",
    "    return ai_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction 1\n",
      "You: I told you something about Paris. Can you recall?\n",
      "Assistant: Bonjour, oui, je me souviens bien que tu vas vivre à Paris ! Tu m'as dit précédemment qu'il est ta ville d'origine ou où tu résides actuellement. C'est une superbe ville avec de nombreuses attractions, comme la Tour Eiffel, le Louvre et Notre-Dame. Je t'espère que tu apprécies la vie à Paris !\n",
      "------------------------------\n",
      "Interaction 2\n",
      "You: Do you remember what I told you about myself?\n",
      "Assistant: Oui, je me souviens de ce que tu m'as dit à propos de toi-même. Tu t'appelles... (mentionner le nom)\n",
      "\n",
      "Au revoir et ne oublie pas mes détails pour la prochaine fois.\n",
      "------------------------------\n",
      "Interaction 3\n",
      "You: Tell me something about my name and where I live.\n",
      "Assistant: Oui, je te rappelle ton nom, c'est [Ton Nom]. Tu habites à Paris, une ville merveilleuse et historique. En ce qui concerne ton nom, il est important de savoir que \"Nom\" en français est un mot très commun et utilisé pour désigner le nom d'une personne ou d'un objet. Par exemple, on dit \"Je m'appelle Jean\", signifiant \"Je suis appelé Jean\". Encore une fois, mon ami, je t'aime de tout mon cœur!\n",
      "------------------------------\n",
      "Interaction 4\n",
      "You: Hello, my name is Alex.\n",
      "Assistant: Bonjour, je suis Alex. Oui, je te rappelle ton nom et tes informations. Tu m'as dit qu'habites à Paris. Mais regarde, je n'ai pas toute ma mémoire sur toi. Pourriez-tu me le rappeler de plus ample? Je sais que tu as également partagé des détails concernant toi-même, mais je ne peux pas les retenir toutes les fois.\n",
      "------------------------------\n",
      "Interaction 5\n",
      "You: Can you remember my name?\n",
      "Assistant: Oui, je t'ai bien compris. Je te rappelle ton nom [nom de l'utilisateur]. Et oui, je me souviens également des détails que tu m'avais donnés à propos de toi précédemment. Au revoir, et n'oublie pas de me rejoindre prochainement.\n",
      "------------------------------\n",
      "Interaction 6\n",
      "You: Remember that I live in Paris.\n",
      "Assistant: Êtes-vous en mesure de me faire un appel en utilisant mon nom? Je sais que vous habitez à Paris. Bonjour! J'ai très bien mémorisé votre visage. Tu m'as dit que tu y vivais, et j'y ai bien pris note de vos détails. Au revoir, je te reverrai prochainement pour continuer notre conversation.\n",
      "------------------------------\n",
      "Interaction 7\n",
      "You: Where do I live?\n",
      "Assistant: Oui, je peux te rappeler ton nom puisque tu l'as précisé dans ta question. Tu habites à Paris, comme moi.\n",
      "\n",
      "Comment t'appelle-t-on ?\n",
      "------------------------------\n",
      "Interaction 8\n",
      "You: What is the capital of France?\n",
      "Assistant: Bonjour, oui, je suis en mesure de t'appeler d'après ton nom ! Tu me l'as dit précédemment que le capital de la France est Paris où je te dis que j'habite également. Mais pour répondre à ta question, le nom de la capitale de la France est Paris. À bientôt pour continuer notre conversation !\n",
      "------------------------------\n",
      "Interaction 9\n",
      "You: Can you summarize what we discussed earlier?\n",
      "Assistant: Bonjour ! Nous avons discuté de la ville où tu vis, à savoir Paris. Tu m'as également partagé des informations personnelles. On va continuer notre conversation prochainement.\n",
      "------------------------------\n",
      "Interaction 10\n",
      "You: Goodbye, and remember my details for next time.\n",
      "Assistant: Au revoir, et soyez bien sûr de me retrouver à la prochaine occasion. Oui, je tiens très bien à toi, en particulier à ton nom : [Votre Nom]. Et oui, je t'ai gardé dans mes souvenirs ce que tu m'as dit à propos de toi. J'espère que nous pourrons continuer notre discussion à la prochaine fois !\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "interactions = [\n",
    "    \"I told you something about Paris. Can you recall?\",\n",
    "    \"Do you remember what I told you about myself?\",\n",
    "    \"Tell me something about my name and where I live.\",\n",
    "    \"Hello, my name is Alex.\",\n",
    "    \"Can you remember my name?\",\n",
    "    \"Remember that I live in Paris.\",\n",
    "    \"Where do I live?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Can you summarize what we discussed earlier?\",\n",
    "    \"Goodbye, and remember my details for next time.\"\n",
    "]\n",
    "\n",
    "for i, user_input in enumerate(interactions, 1):\n",
    "    print(f\"Interaction {i}\")\n",
    "    print(f\"You: {user_input}\")\n",
    "    reply = chat_with_memory(user_input)\n",
    "    print(f\"Assistant: {reply}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
